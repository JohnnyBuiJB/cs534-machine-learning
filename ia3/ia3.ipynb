{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "df_train = pd.read_csv(\"IA3-train.csv\")\n",
    "df_val = pd.read_csv(\"IA3-dev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 0: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_pos_tweets = df_train[df_train['sentiment'] == 1]\n",
    "df_pos_tweets\n",
    "\n",
    "df_neg_tweets = df_train[df_train['sentiment'] == 0]\n",
    "df_neg_tweets\n",
    "\n",
    "pos_vectorizer = CountVectorizer()\n",
    "neg_vectorizer = CountVectorizer()\n",
    "pos_tweets_token_counts = pos_vectorizer.fit_transform(df_pos_tweets['text'])\n",
    "neg_tweets_token_counts = neg_vectorizer.fit_transform(df_neg_tweets['text'])\n",
    "\n",
    "pos_tweets_words = pos_vectorizer.get_feature_names()\n",
    "neg_tweets_words = neg_vectorizer.get_feature_names()\n",
    "print(len(pos_tweets_words))\n",
    "print(len(neg_tweets_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df_pos_tweets = df_val[df_val['sentiment'] == 1]\n",
    "df_pos_tweets\n",
    "\n",
    "df_neg_tweets = df_val[df_val['sentiment'] == 0]\n",
    "df_neg_tweets\n",
    "\n",
    "pos_vectorizer = CountVectorizer()\n",
    "neg_vectorizer = CountVectorizer()\n",
    "pos_tweets_token_counts = pos_vectorizer.fit_transform(df_pos_tweets['text'])\n",
    "neg_tweets_token_counts = neg_vectorizer.fit_transform(df_neg_tweets['text'])\n",
    "\n",
    "pos_tweets_words = pos_vectorizer.get_feature_names()\n",
    "neg_tweets_words = neg_vectorizer.get_feature_names()\n",
    "print(len(pos_tweets_words))\n",
    "print(len(neg_tweets_words))\n",
    "\n",
    "print(len(neg_tweets_words) / (len(neg_tweets_words) + len(pos_tweets_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another important note is the imbalance of the training data. The negative comments are present with approximately 0.71 ratio in the training set and 0.72 in the validation set. Initially, we were not aware of the issue untill we observed some odd trends of its number of support vectors when C increases. Further testing on other metrics confirmed that it was indeed an accuracy paradox. In particular, its validation recall is 0.47 while its balanced validation accuracy score (the average of recall obtained on each class) is only 0.73, which is slightly higher than blindly classifying all as negative (that would yield 0.72 validation accuracy).\n",
    "\n",
    "Accuracy paradox is a situation in which a model has excellent accuracy that only refects the underlying class distribution. It is often caused by imbalance data set, which is very common and expected. For example, the data set for fraudulent transaction classification is probably unbalanced because most of the transactions are not fraudulent.\n",
    "\n",
    "One of the remedies for this problem is using cost-sensitive training, or class-weighted SVMs, in which costs for each class are different based on the ratio of them. Unsurprisingly, Scikit-learn does support this method to tackle this common problem. Training the model using SVC.fit() with the option class_weight=\"balanced\" resulted in much better performance. Specifically, the model balanced validation accuracy went up to 0.82, whereas its recall increased to 0.65. Its validation accuracy was also improved from 0.89 to 0.92.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IA3_skeleton_code import getMaxes\n",
    "\n",
    "sum_pos_tweets_token_counts = pos_tweets_token_counts.sum(axis=0).tolist()[0]\n",
    "sum_neg_tweets_token_counts = neg_tweets_token_counts.sum(axis=0).tolist()[0]\n",
    "\n",
    "pos_tweets_most_freq_indices = getMaxes(sum_pos_tweets_token_counts, 10)\n",
    "neg_tweets_most_freq_indices = getMaxes(sum_neg_tweets_token_counts, 10)\n",
    "\n",
    "print(\"The 10 most frequent words in the positive comments: \")\n",
    "for i in pos_tweets_most_freq_indices:\n",
    "    print(\"\\\"%s\\\" occurs %d times\" % (pos_tweets_words[i], sum_pos_tweets_token_counts[i]))\n",
    "\n",
    "print(\"==============================\")\n",
    "\n",
    "print(\"The 10 most frequent words in the negetive comments: \")\n",
    "for i in neg_tweets_most_freq_indices:\n",
    "    print(\"\\\"%s\\\" occurs %d times\" % (neg_tweets_words[i], sum_neg_tweets_token_counts[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words seem not to semantically correlate with the label of the comments. \n",
    "For example, the most frequent words such as \"the\", \"to\", \"you\", and \"for\" are \n",
    "neutral, suggesting neither negativity nor positivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pos_tfidfvectorizer = TfidfVectorizer(use_idf=True, lowercase=True)\n",
    "neg_tfidfvectorizer = TfidfVectorizer(use_idf=True, lowercase=True)\n",
    "pos_tweets_tfidf = pos_tfidfvectorizer.fit_transform(df_pos_tweets['text'])\n",
    "neg_tweets_tfidf = neg_tfidfvectorizer.fit_transform(df_neg_tweets['text'])\n",
    "\n",
    "pos_tweets_words = pos_tfidfvectorizer.get_feature_names()\n",
    "neg_tweets_words = neg_tfidfvectorizer.get_feature_names()\n",
    "\n",
    "sum_pos_tweets_tfidf = pos_tweets_tfidf.sum(axis=0).tolist()[0]\n",
    "sum_neg_tweets_tfidf = neg_tweets_tfidf.sum(axis=0).tolist()[0]\n",
    "\n",
    "pos_tweets_most_freq_indices = getMaxes(sum_pos_tweets_tfidf, 10)\n",
    "neg_tweets_most_freq_indices = getMaxes(sum_neg_tweets_tfidf, 10)\n",
    "\n",
    "print(\"The 10 most frequent words in the positive comments: \")\n",
    "for i in pos_tweets_most_freq_indices:\n",
    "    print(\"\\\"%s\\\" occurs %d times\" % (pos_tweets_words[i], sum_pos_tweets_tfidf[i]))\n",
    "\n",
    "print(\"==============================\")\n",
    "\n",
    "print(\"The 10 most frequent words in the negetive comments: \")\n",
    "for i in neg_tweets_most_freq_indices:\n",
    "    print(\"\\\"%s\\\" occurs %d times\" % (neg_tweets_words[i], sum_neg_tweets_tfidf[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: LINEAR SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. C value results the best validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IA3_skeleton_code import trainSVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def trainSVM(X_train, y_train, X_val, y_val, c, kernel, deg=3):\n",
    "    \"\"\"\n",
    "    Description: scikit learn linearSVC wrapper\n",
    "    Param:\n",
    "        X_train  [in]: training data\n",
    "        y_train  [in]: training label\n",
    "        X_val    [in]: validation data\n",
    "        y_val    [in]: validation label\n",
    "        c        [in]: Regularization parameter. The strength of the \n",
    "                       regularization is inversely proportional to C. Must be \n",
    "                       strictly positive.\n",
    "        kernel   [in]: Kernel type for SVC\n",
    "        deg      [in]: degree (only for poly kernel) - if not poly, this is \n",
    "                       ignored (default param set to sklearn default = 3)\n",
    "    Return: training accuracy, validation accuracy, and number of SV's (respectively)\n",
    "    \"\"\"\n",
    "    n_train = X_train.shape[0]\n",
    "    n_val = X_val.shape[0]\n",
    "    \n",
    "    svm = SVC(C=c, kernel=kernel, degree=deg, max_iter=25000)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train = svm.predict(X_train)\n",
    "    y_pred_val = svm.predict(X_val)\n",
    "    \n",
    "    acc_train = (n_train - np.count_nonzero(y_pred_train - y_train)) / n_train\n",
    "    acc_val = (n_val - np.count_nonzero(y_pred_val - y_val)) / n_val\n",
    "    \n",
    "    return acc_train, acc_val, svm.n_support_\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer(use_idf=True, lowercase=True)\n",
    "\n",
    "# X_train = tfidfvectorizer.fit_transform(df_train['text']).toarray()\n",
    "X_train = tfidfvectorizer.fit_transform(df_train['text'])\n",
    "y_train = df_train['sentiment']\n",
    "\n",
    "X_val = tfidfvectorizer.transform(df_val['text']).toarray()\n",
    "y_val = df_val['sentiment']\n",
    "\n",
    "exp = range(-4,5)\n",
    "c = list(map(lambda x: 10**(x), exp))\n",
    "\n",
    "n_val = len(y_val)\n",
    "acc_train = {}\n",
    "acc_val = {}\n",
    "SVMs = {}\n",
    "for _ in c:\n",
    "    acc_train[_], acc_val[_], SVMs[_] = trainSVM(X_train, y_train, X_val, y_val, _, \n",
    "                                        \"linear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trend of training and validation performance in regards with c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot(exp, list(acc_train.values()), label=\"Training\")\n",
    "plt.plot(exp, list(acc_val.values()), label=\"Validation\")\n",
    "\n",
    "plt.xlabel(\"i\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy in regards to c = 10^i\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Relationship between the number of support vectors and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IA3_skeleton_code import plotNSV\n",
    "\n",
    "plotNSV(exp, SVMs, \"Linear SVM\", \"lsvmNSV.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like best c values are in the range [0.1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_val = {}\n",
    "acc_train = {}\n",
    "SVMs = {}\n",
    "l = 0.1\n",
    "r = 1\n",
    "\n",
    "max_depth = 15\n",
    "cur_depth = 0\n",
    "\n",
    "while cur_depth <= max_depth:\n",
    "    if l not in acc_val.keys():\n",
    "        acc_train[l], acc_val[l], SVMs[l] = trainSVM(X_train, y_train, X_val, \n",
    "                                                     y_val, l, \"linear\")\n",
    "        \n",
    "    if r not in acc_val.keys():\n",
    "        acc_train[r], acc_val[r], SVMs[r] = trainSVM(X_train, y_train, X_val, \n",
    "                                                     y_val, r, \"linear\")\n",
    "    \n",
    "    m = (l + r) / 2\n",
    "    acc_train[m], acc_val[m], SVMs[m] = trainSVM(X_train, y_train, X_val, \n",
    "                                                 y_val, m, \"linear\")\n",
    "    \n",
    "    acc_val_max = max(acc_val[m], acc_val[r], acc_val[l])\n",
    "    \n",
    "    if acc_val_max == acc_val[m]:\n",
    "        l = (m + l) / 2\n",
    "        r = (m + r) / 2\n",
    "    elif acc_val_max == acc_val[l]:\n",
    "        r = m\n",
    "    else:\n",
    "        l = m\n",
    "    \n",
    "    cur_depth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.figure(figsize=(10,6))\n",
    "ax1 = plt.subplot(1,2,1)\n",
    "\n",
    "ax1.scatter(list(acc_val.keys()), list(acc_val.values()))\n",
    "plt.xlabel(\"C\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "plt.title(\"Validation accuracy in regards to c\")\n",
    "\n",
    "ax2 = plt.subplot(1,2,2)\n",
    "ax2.set(xlim=(0.7, 1.1), ylim=(0.92, 0.93))\n",
    "ax2.scatter(list(acc_val.keys()), list(acc_val.values()))\n",
    "plt.title(\"Zoomed in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with highest validation accuracy\n",
    "best_c = max(acc_val, key=acc_val.get)\n",
    "\n",
    "print(\"The best model has accuracy of %f with C = %f\" % (acc_val[best_c], best_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I looks like C values in the neighbor of 0.88 yields models with the highest \n",
    "accuracies, 0.9312."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "for c, (_, svs) in zip(SVMs.keys(), SVMs.items()):\n",
    "    sv = sum(svs)\n",
    "    plt.scatter(c, sv, s=sv*0.05)\n",
    "\n",
    "plt.xlabel(\"c\")\n",
    "plt.ylabel(\"Support Vector Counts\")\n",
    "plt.title(\"Number of SV\\'s for c in range [0,1]| \" + \"Linear SVM\")\n",
    "plt.savefig(\"lsvmNSV.jpg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15a1e72ba773099527125ed58d42668c54ab9c98f183bb59c28e4748fcdd480d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
